{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79317fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 4s 6ms/step - loss: 1.1401 - accuracy: 0.8756 - val_loss: 0.6007 - val_accuracy: 0.9169\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5617 - accuracy: 0.9210 - val_loss: 0.5137 - val_accuracy: 0.9263\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4904 - accuracy: 0.9303 - val_loss: 0.4530 - val_accuracy: 0.9384\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4525 - accuracy: 0.9365 - val_loss: 0.4226 - val_accuracy: 0.9412\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4234 - accuracy: 0.9410 - val_loss: 0.4194 - val_accuracy: 0.9389\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4036 - accuracy: 0.9451 - val_loss: 0.3669 - val_accuracy: 0.9541\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3834 - accuracy: 0.9477 - val_loss: 0.3772 - val_accuracy: 0.9491\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3681 - accuracy: 0.9491 - val_loss: 0.3437 - val_accuracy: 0.9580\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.9517 - val_loss: 0.3327 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3427 - accuracy: 0.9523 - val_loss: 0.3273 - val_accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow library\n",
    "import tensorflow as tf \n",
    "\n",
    "# Load the data # Load MNIST dataset\n",
    "'''\n",
    "loads the MNIST dataset using the load_data() function provided by Keras, a high-level API of TensorFlow.\n",
    "The MNIST dataset contains 70,000 images of handwritten digits that are split into \n",
    "60,000 training images and 10,000 testing images.\n",
    "'''\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data() \n",
    "\n",
    "# Preprocess the data\n",
    "'''\n",
    "Preprocess the data. The images are first reshaped from a 3D array (28x28 pixels) to a 2D array (784 pixels).\n",
    "Then, the pixel values are normalized to be between 0 and 1 by dividing by 255. \n",
    "The labels are converted to one-hot encoding format using the to_categorical() function provided by Keras.\n",
    "This is done to make it easier for the model to classify the images into 10 different classes (one for each digit).\n",
    "'''\n",
    "# Reshape and normalize training data\n",
    "train_data = train_data.reshape((60000, 784)) / 255.0 \n",
    "# Reshape and normalize testing data\n",
    "test_data = test_data.reshape((10000, 784)) / 255.0 \n",
    "# Convert training labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels) \n",
    "# Convert testing labels to one-hot encoding\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels) \n",
    "\n",
    "# Define the model architecture\n",
    "'''\n",
    "This code defines the architecture of the neural network model.\n",
    "The Sequential() function is used to create a sequential model, meaning that the layers are added in sequence.\n",
    "Three fully connected layers are defined using the Dense() function.\n",
    "The first layer has 128 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The second layer has 64 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The third and final layer has 10 units, softmax activation, and is used for the classification task.\n",
    "'''\n",
    "model = tf.keras.models.Sequential([ # Define sequential model\n",
    "         #Add a fully connected layer with 128 units, ReLU activation, and L2 regularization\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        # Add another fully connected layer with 64 units,ReLU activation, and L2 regularization\n",
    "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)), \n",
    "        # Add a final output layer with 10 units (one for each class), softmax activation\n",
    "        tf.keras.layers.Dense(10, activation='softmax') \n",
    "        ])\n",
    "\n",
    "# Compile the model\n",
    "'''\n",
    "This code compiles the model. The compile() function configures the model for training by specifying the optimizer,\n",
    "loss function, and metrics to monitor during training. In this case, the Adam optimizer is used with a \n",
    "learning rate of 0.001, categorical cross-entropy is used as the loss function, and accuracy is monitored during training.\n",
    "'''\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # Use Adam optimizer with learning rate 0.001\n",
    "                loss='categorical_crossentropy', # Use categorical cross-entropy loss function\n",
    "                metrics=['accuracy']) # Monitor accuracy during training\n",
    "\n",
    "# Train the model\n",
    "'''\n",
    "This code trains the model using the fit() function. The training data and labels are passed in as arguments,along with \n",
    "the number of epochs to train for, the batch size to use, and the validation data to use for monitoring model performance \n",
    "during training. The fit() function returns a history object that contains information about the training process, such as \n",
    "the loss and accuracy at each epoch. The purpose of this program is to demonstrate how to implement a neural network model \n",
    "for image classification using TensorFlow/Keras. The model uses regularization techniques to prevent overfitting and achieves \n",
    "high accuracy on the MNIST dataset.\n",
    "'''\n",
    "history = model.fit(train_data, train_labels, epochs=10, batch_size=128,\n",
    "        # Train the model for 10 epochs,using batches of size 128, and validate on the testing data at the end of each epoch\n",
    "                    validation_data=(test_data, test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
